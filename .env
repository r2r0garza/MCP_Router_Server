# MCP Router Server Environment Example

# Core LLM provider selection
LLM_PROVIDER=azure #openai, lmstudio, openrouter, ollama, anthropic, azure
MODEL= gpt-4o-mini

# LM Studio (local inference endpoint)
LMSTUDIO_URL=http://localhost:1234/v1/chat/completions
LMSTUDIO_API_KEY=hermes-3-llama-3.1-8b

ANTHROPIC_API_KEY=sk-ant-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
# Anthropic Model = claude-3-5-sonnet-20241022

OPENROUTER_API_KEY=sk-or-v1-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
# Openrouter Model = openai/gpt-4.1

AZURE_FOUNDY_API_KEY=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
AZURE_FOUNDY_DEPLOYMENT=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX #i.e - in https://my-deployment.openai.azure.com, the deployement is my-deployment
VERSION=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX #i.e - 2023-03-15-preview