# MCP Router Server Environment Example

# Core LLM provider selection
LLM_PROVIDER=lmstudio #openai, lmstudio, openrouter, ollama, anthropic, azure
MODEL=openai/gpt-4.1

# LM Studio (local inference endpoint)
LMSTUDIO_URL=http://localhost:1234/v1/chat/completions
LMSTUDIO_API_KEY=hermes-3-llama-3.1-8b

ANTHROPIC_API_KEY=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

OPENROUTER_API_KEY=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

